{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "0    345738\n",
       "1    104438\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df1 = pd.read_csv(\"./data/urldata.csv\", index_col=0)\n",
    "url_df1['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "benign        428103\n",
       "defacement     96457\n",
       "phishing       94111\n",
       "malware        32520\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df2 = pd.read_csv(\"./data/malicious_phish.csv\")\n",
    "url_df2['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url        type  result\n",
       "0                                   br-icloud.com.br    phishing       1\n",
       "1                mp3raid.com/music/krizz_kaliko.html      benign       0\n",
       "2                    bopsecrets.org/rexroth/cr/1.htm      benign       0\n",
       "3  http://www.garage-pirenne.be/index.php?option=...  defacement       1\n",
       "4  http://adventure-nicaragua.net/index.php?optio...  defacement       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_result_col(row):\n",
    "    if(row['type']=='benign'):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "url_df2['result'] = url_df2.apply(gen_result_col, axis=1)\n",
    "url_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450176, 3)\n",
      "(651191, 3)\n"
     ]
    }
   ],
   "source": [
    "print(url_df1.shape)\n",
    "print(url_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_col = ['url', 'result']\n",
    "combined_url_df = pd.concat([url_df1[desired_col], url_df2[url_df2['result'] == 1][desired_col]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673264, 2)\n",
      "result\n",
      "0    345738\n",
      "1    327526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_url_df.shape)\n",
    "print(combined_url_df['result'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url  result\n",
       "0     https://www.google.com       0\n",
       "1    https://www.youtube.com       0\n",
       "2   https://www.facebook.com       0\n",
       "3      https://www.baidu.com       0\n",
       "4  https://www.wikipedia.org       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2314\n"
     ]
    }
   ],
   "source": [
    "max_url_len = 0\n",
    "for index, row in combined_url_df.iterrows():\n",
    "    max_url_len = max(max_url_len, len(row['url']))\n",
    "\n",
    "print(max_url_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662147, 2)\n",
      "result\n",
      "0    345738\n",
      "1    316409\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_url_df = combined_url_df.drop_duplicates()\n",
    "print(combined_url_df.shape)\n",
    "print(combined_url_df['result'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (463502, 2)\n",
      "result\n",
      "0    242203\n",
      "1    221299\n",
      "Name: count, dtype: int64\n",
      "Validation set shape: (99322, 2)\n",
      "result\n",
      "0    51816\n",
      "1    47506\n",
      "Name: count, dtype: int64\n",
      "Test set shape: (99323, 2)\n",
      "result\n",
      "0    51719\n",
      "1    47604\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data, temp_data = train_test_split(combined_url_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split temp_data into validation and test sets\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"Train set shape:\", train_data.shape)\n",
    "print(train_data['result'].value_counts())\n",
    "\n",
    "print(\"Validation set shape:\", val_data.shape)\n",
    "print(val_data['result'].value_counts())\n",
    "\n",
    "print(\"Test set shape:\", test_data.shape)\n",
    "print(test_data['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom_filter2 import BloomFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 221300 #no of items to add \n",
    "p = 0.05 #false positive probability \n",
    "  \n",
    "bloomfilter = BloomFilter(max_elements=n,error_rate=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_data[train_data['result']==1].iterrows():\n",
    "    bloomfilter.add(row['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2614\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for index, row in test_data[test_data['result']==0].iterrows():\n",
    "    if(row['url'] in bloomfilter):\n",
    "        fp+=1\n",
    "\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050542353873818134\n"
     ]
    }
   ],
   "source": [
    "fpr = fp/51719\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3159332275390625\n"
     ]
    }
   ],
   "source": [
    "print(bloomfilter.num_bits_m / (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(bloomfilter.num_probes_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(set(\"\".join(combined_url_df['url'])))}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 0, '{': 1, '¸': 2, '$': 3, '\\x9b': 4, 'O': 5, 'ด': 6, '9': 7, '#': 8, '\\x15': 9, '\\x07': 10, 'B': 11, 'A': 12, 'c': 13, '\\xa0': 14, 'ל': 15, 'Š': 16, 'ฟ': 17, 'ו': 18, '\\x02': 19, '\\x1b': 20, 'î': 21, '\\x9c': 22, '\\x18': 23, '§': 24, 'Ü': 25, 'ศ': 26, '\\x8a': 27, '\\x9d': 28, 'อ': 29, '÷': 30, '\\n': 31, 'V': 32, '\\x8c': 33, 'e': 34, 'ญ': 35, '\\x1d': 36, 'Ú': 37, '\\x88': 38, 'บ': 39, 'p': 40, 'R': 41, 'Ã': 42, '\\x92': 43, '¢': 44, '‰': 45, '`': 46, 'Ó': 47, '\\x81': 48, 'ה': 49, 'º': 50, '¯': 51, '\\x12': 52, '“': 53, '-': 54, '^': 55, 'y': 56, '”': 57, 'ต': 58, 'h': 59, '£': 60, 'ว': 61, 'ผ': 62, '\\x82': 63, 'ื': 64, 'þ': 65, '‚': 66, 'í': 67, 'ู': 68, 'á': 69, 'ฅ': 70, 'W': 71, 'Â': 72, 'Þ': 73, 'า': 74, 'כ': 75, 'ë': 76, 'Ë': 77, '่': 78, '\\x7f': 79, '!': 80, '©': 81, '\\x8f': 82, 'ๅ': 83, '成': 84, 'Ç': 85, 'ถ': 86, '±': 87, '\\x14': 88, 'Q': 89, 'ข': 90, 'Õ': 91, '¾': 92, '\\x80': 93, 'ง': 94, '\\x0f': 95, '•': 96, 'Æ': 97, '_': 98, 'ö': 99, '用': 100, '\\x03': 101, '}': 102, '\\x9e': 103, 'è': 104, 'ç': 105, '6': 106, 'i': 107, 'ส': 108, 'จ': 109, 'ล': 110, 'Ñ': 111, '\\x0c': 112, 'b': 113, '\\x16': 114, 'X': 115, 'ì': 116, 'É': 117, 'j': 118, 'ณ': 119, 'ฉ': 120, 'û': 121, 'â': 122, '>': 123, 'µ': 124, '使': 125, '傅': 126, 'Ò': 127, 'ü': 128, '\\x19': 129, '½': 130, '\\x17': 131, '\\x0b': 132, '\\x08': 133, 'ช': 134, '*': 135, '\\x04': 136, 'Ì': 137, '\\x06': 138, 'l': 139, 'ฬ': 140, '…': 141, '\\x8b': 142, '–': 143, 'Ø': 144, 'י': 145, '—': 146, '\\x98': 147, 'ฃ': 148, 'm': 149, 'à': 150, '\\x1f': 151, '@': 152, '\\x87': 153, 'ò': 154, 'F': 155, '7': 156, 'ת': 157, '\\x91': 158, 't': 159, 'a': 160, '\\u200a': 161, 'P': 162, '\\r': 163, 'ป': 164, 'Ê': 165, '·': 166, 'ש': 167, '\\x86': 168, 'ึ': 169, 'C': 170, 'น': 171, '\\x93': 172, '»': 173, 'š': 174, 'ั': 175, 'ไ': 176, '¹': 177, 'ร': 178, '²': 179, '\\x01': 180, 'ฦ': 181, 'U': 182, 'ø': 183, 'Î': 184, 'ุ': 185, '\\x0e': 186, '?': 187, '\\uf1dc': 188, 'ท': 189, 'Û': 190, '\\x10': 191, 'ט': 192, 'ý': 193, '0': 194, 'T': 195, 'ธ': 196, '3': 197, 'Y': 198, '×': 199, 'ฝ': 200, '8': 201, '³': 202, 'ะ': 203, 'Ö': 204, '\\x84': 205, '=': 206, '¦': 207, 'È': 208, '[': 209, 'ª': 210, 'ำ': 211, 'ฑ': 212, 'ˆ': 213, '¨': 214, 'ÿ': 215, '®': 216, 'ซ': 217, '\\x1c': 218, 'D': 219, 'o': 220, 'G': 221, ' ': 222, 'ี': 223, 'Ù': 224, 'g': 225, 'z': 226, '5': 227, '\"': 228, 'Å': 229, ']': 230, '’': 231, 'เ': 232, 'ù': 233, '\\x89': 234, 'x': 235, 'N': 236, '\\x99': 237, '¿': 238, 'ฎ': 239, 'ƒ': 240, '\\x94': 241, 'ห': 242, 'ย': 243, '%': 244, 'ฮ': 245, '(': 246, '|': 247, 'ג': 248, 's': 249, '\\x1a': 250, 'õ': 251, '\\t': 252, '.': 253, 'Ô': 254, 'ô': 255, '<': 256, '\\\\': 257, '&': 258, 'À': 259, '\\x95': 260, \"'\": 261, 'Ð': 262, 'ä': 263, 'ï': 264, '\\x9a': 265, '/': 266, 'w': 267, 'L': 268, 'M': 269, '\\xad': 270, 'J': 271, 'พ': 272, 'ž': 273, '¡': 274, 'k': 275, '4': 276, 'Ï': 277, '¶': 278, '\\x83': 279, '\\x96': 280, 'ã': 281, 'ฒ': 282, '°': 283, 'ฤ': 284, 'ฐ': 285, 'ฏ': 286, '¼': 287, '~': 288, 'E': 289, '¥': 290, 'ฺ': 291, '๓': 292, 'ן': 293, 'ק': 294, 'K': 295, ':': 296, 'f': 297, 'r': 298, 'ค': 299, 'ñ': 300, '拠': 301, '\\x11': 302, 'Ä': 303, 'ב': 304, 'ก': 305, 'ð': 306, '\\x1e': 307, 'S': 308, '2': 309, 'H': 310, 'n': 311, ';': 312, 'ê': 313, 'Z': 314, 'Í': 315, '¬': 316, '\\x9f': 317, '\\x05': 318, '\\x8d': 319, '\\x97': 320, 'ח': 321, 'ר': 322, 'ิ': 323, '™': 324, 'é': 325, '¤': 326, 'I': 327, 'd': 328, '�': 329, '\\x85': 330, ')': 331, 'u': 332, '+': 333, 'v': 334, '\\x90': 335, 'Ý': 336, 'ß': 337, 'å': 338, '品': 339, '€': 340, ',': 341, 'ú': 342, 'Á': 343, '\\x8e': 344, '´': 345, 'ฌ': 346, '1': 347, 'æ': 348, 'ó': 349, '«': 350, 'צ': 351, '\\x13': 352}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(char_to_idx)\n",
    "print((char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from util import CharacterLevelDataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharacterLevelDataset(Dataset):\n",
    "    def __init__(self, data, labels, max_seq_length):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.max_seq_length = max_seq_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Truncate or pad sequences to max_seq_length\n",
    "        sequence = self.data[idx][:self.max_seq_length].ljust(self.max_seq_length)\n",
    "        # Convert sequence to tensor of character indices\n",
    "        sequence_tensor = torch.tensor([char_to_idx[char] for char in sequence])\n",
    "        # Convert label to tensor\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return sequence_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 16\n",
    "# train_data = train_data.head(10)\n",
    "train_dataset = CharacterLevelDataset(train_data['url'].values, train_data['result'].values, max_seq_len)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterLevelGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim):\n",
    "        super(CharacterLevelGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size,  batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        # print(embedded.shape)\n",
    "        output, _ = self.gru(embedded)\n",
    "        # print(output.shape)\n",
    "        last_output = output[:, -1, :]\n",
    "        # print(last_output.shape)\n",
    "        output = self.fc(last_output)  # Use only the last output of the sequence\n",
    "        # print(output.shape)\n",
    "        output = self.sigmoid(output)  # Apply sigmoid activation function\n",
    "        # print(output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 16\n",
    "embedding_dim = 32\n",
    "model = CharacterLevelGRU(vocab_size, hidden_size, embedding_dim)\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/28969 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0168\n",
      "Final Average Loss: 0.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "total_batches = len(dataloader)\n",
    "running_loss = 0.0\n",
    "\n",
    "# Apply tqdm to the epoch loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Reset the running loss for each epoch\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Apply tqdm to the dataloader loop\n",
    "    batch_progress = tqdm(enumerate(dataloader), total=total_batches, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    for i, (data, labels) in batch_progress:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), labels)  # Compute loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch after all batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / total_batches:.4f}\")\n",
    "\n",
    "# Print final average loss for all epochs\n",
    "print(f\"Final Average Loss: {running_loss / total_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.to('cpu')\n",
    "\n",
    "# Save model state dictionary\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28969%16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
